# TODO List - AllSides Next Project

## In Progress

### 1. Task Cancellation on Client Disconnect
**Status**: ðŸ”§ In Progress  
**Priority**: MEDIUM  
**Issue**: Background LLM tasks continue running when client disconnects, causing resource leaks.

**Implementation Required**:
- [ ] Add client disconnect detection in streaming views
- [ ] Implement task cancellation for asyncio.gather() operations
- [ ] Add proper cleanup for WebSocket connections

**Files to Update**:
- `backend/api/views.py` (client disconnect handling in stream_query_view)

---

## Completed

### 1. Critical Async Architecture Fixes
**Status**: âœ… Completed  
**Date**: June 11, 2025  
**Details**: 
- **FIXED: Redis Async Compatibility** - Replaced synchronous redis.Redis with redis.asyncio.Redis
- **FIXED: Sequential LLM Tasks** - Replaced sequential await with asyncio.gather(*tasks, return_exceptions=True)
- **FIXED: Cascade Failures** - Added proper error handling for partial LLM failures
- **FIXED: Race Conditions** - Implemented immutable task orchestration pattern
- **PERFORMANCE**: LLM enhancements now run in parallel (5-10x faster)
- **RESILIENCE**: Single LLM task failure no longer breaks entire response

### 2. Async Flow Architecture Analysis
**Status**: âœ… Completed  
**Date**: June 11, 2025  
**Details**: 
- Verified async patterns between Junto API, local vLLM, and frontend streaming
- Confirmed proper SSE implementation with ReadableStream parsing
- Identified WebSocket with HTTP polling fallback working correctly
- Validated thread pool usage for CPU-bound LLM operations
- Frontend handles progressive data display with proper error handling

### 1. Async Parallelization of Evidence Search
**Status**: âœ… Completed  
**Date**: June 11, 2025  
**Details**: 
- Implemented parallel evidence search using asyncio.gather()
- Added aesthetic progress tracking
- Fixed event loop conflicts with Django
- Added comprehensive error handling
- Performance improved from O(n) to O(1)

### 2. Remove Mock Enhancement Data from Frontend
**Status**: âœ… Completed  
**Date**: June 11, 2025  
**Details**:
- Removed mockEnhancements.ts file
- Cleaned up all imports from components
- Frontend now uses real LLM data exclusively

### 3. Test Mode with 2-Position Limitation
**Status**: âœ… Completed  
**Date**: June 11, 2025  
**Details**:
- Added temporary limitation to process only first 2 positions
- Reduces testing time from 30-60s to 5-10s
- Marked with TODO comments for easy removal

---

## Planned Features

### 1. Full Position Processing (Remove Test Limitation)
**Status**: ðŸ“‹ Planned  
**Priority**: MEDIUM  
**Details**: Remove the 2-position limitation after testing is complete

### 2. Connection Pooling for External APIs
**Status**: ðŸ“‹ Planned  
**Priority**: LOW  
**Details**: Implement HTTP connection pooling for better performance

### 3. Retry Logic with Exponential Backoff
**Status**: ðŸ“‹ Planned  
**Priority**: LOW  
**Details**: Add retry logic for failed evidence searches

### 4. Enhanced Caching Strategy
**Status**: ðŸ“‹ Planned  
**Priority**: MEDIUM  
**Details**: Implement parallel-aware caching strategies

### 5. Rate Limiting for External APIs
**Status**: ðŸ“‹ Planned  
**Priority**: LOW  
**Details**: Add smart rate limiting to prevent API throttling

---

## Notes

- Always update this file when starting/completing features
- Mark items that require deeper thought with ðŸ¤”
- Use ðŸ”§ for in-progress, âœ… for completed, ðŸ“‹ for planned
- Add date when completed for tracking